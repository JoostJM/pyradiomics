{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello Feature Class example: using the feature classes to calculate features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows how to use the Radiomics package to directly instantiate the feature classes for feature extraction. \n",
    "Note that this is not the intended standard use. For an example on the standard use with feature extractor, see the `helloRadiomics` example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import collections\n",
    "import SimpleITK as sitk\n",
    "import numpy\n",
    "import six\n",
    "import radiomics\n",
    "from radiomics import firstorder, glcm, imageoperations, shape, glrlm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the test case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing data is contained in the pyradiomics/data folder, while this file is in the pyradiomics/bin/Notebooks folder. \n",
    "\n",
    "The next line of code gets the location of the current path and gets the location of the data as a relative path by going up two folders (\"..\") and then move into the data folders (\"data\").\n",
    "\n",
    "For this to work, the current active directory should be pyradiomics/bin/notebooks, which is the case if this file is run from the pyradiomics/bin/Notebooks folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testCase = 'brain1'\n",
    "dataDir = os.path.join(os.path.abspath(\"\"), \"..\", \"..\", \"data\")\n",
    "imageName = os.path.join(dataDir, testCase + '_image.nrrd')\n",
    "maskName = os.path.join(dataDir, testCase + '_label.nrrd')\n",
    "\n",
    "if not os.path.exists(imageName):\n",
    "  print('Error: problem finding input image', imageName)\n",
    "if not os.path.exists(maskName):\n",
    "  print('Error: problem finding input labelmap', maskName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = sitk.ReadImage(imageName)\n",
    "mask = sitk.ReadImage(maskName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraction Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "kwargs['binWidth'] = 25\n",
    "kwargs['resampledPixelSpacing'] = None\n",
    "# kwargs['resampledPixelSpacing'] = [3, 3, 3]  # This is an example for defining resampling (voxels with size 3x3x3mm)\n",
    "kwargs['interpolator'] = 'sitkBSpline'\n",
    "kwargs['verbose'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If enabled, resample the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resample if necessary\n",
    "if kwargs['interpolator'] != None and kwargs['resampledPixelSpacing'] != None:\n",
    "  image, mask = imageoperations.resampleImage(image, mask, kwargs['resampledPixelSpacing'], kwargs['interpolator'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Calculate features using original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Crop the image\n",
    "# bb is the bounding box, upon which the image and mask are cropped\n",
    "croppedImage, croppedMask, bb = imageoperations.cropToTumorMask(image, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Firstorder features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "firstOrderFeatures = firstorder.RadiomicsFirstOrder(croppedImage, croppedMask, **kwargs)\n",
    "\n",
    "# Set the features to be calculated\n",
    "firstOrderFeatures.enableFeatureByName('Mean', True)\n",
    "# firstOrderFeatures.enableAllFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will calculate the following first order features: \n",
      "Mean\n",
      "\n",
      "    Calculate the Mean Value for the image array.\n",
      "\n",
      "    :math:`mean = \\frac{1}{N}\\displaystyle\\sum^{N}_{i=1}{\\textbf{X}(i)}`\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Print out the docstrings of the enabled features\n",
    "print('Will calculate the following first order features: ')\n",
    "for f in firstOrderFeatures.enabledFeatures.keys():\n",
    "  print(f)\n",
    "  print(eval('firstOrderFeatures.get' + f + 'FeatureValue.__doc__'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating first order features...\n",
      "done\n",
      "Calculated first order features: \n",
      "   Mean : 825.235436307\n"
     ]
    }
   ],
   "source": [
    "# Calculate the features and print(out result)\n",
    "print('Calculating first order features...',)\n",
    "firstOrderFeatures.calculateFeatures()\n",
    "print('done')\n",
    "\n",
    "print('Calculated first order features: ')\n",
    "for (key, val) in six.iteritems(firstOrderFeatures.featureValues):\n",
    "  print('  ', key, ':', val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Shape Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shapeFeatures = shape.RadiomicsShape(croppedImage, croppedMask, **kwargs)\n",
    "\n",
    "# Set the features to be calculated\n",
    "# shapeFeatures.enableFeatureByName('Volume', True)\n",
    "shapeFeatures.enableAllFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will calculate the following shape features: \n",
      "Maximum3DDiameter\n",
      "\n",
      "    Calculate the largest pairwise euclidean distance between tumor surface voxels.\n",
      "    Also known as Feret Diameter.\n",
      "    \n",
      "Compactness2\n",
      "\n",
      "    Calculate the Compactness (2) of the tumor region.\n",
      "\n",
      "    :math:`compactness\\ 2 = 36\\pi\\frac{V^2}{A^3}`\n",
      "\n",
      "    Compactness 2 is a measure of how compact the shape of the tumor is\n",
      "    relative to a sphere (most compact). It is a dimensionless measure,\n",
      "    independent of scale and orientation. This is a measure of the compactness\n",
      "    of the shape of the image ROI.\n",
      "    \n",
      "Compactness1\n",
      "\n",
      "    Calculate the compactness (1) of the tumor region.\n",
      "\n",
      "    :math:`compactness\\ 1 = \\frac{V}{\\sqrt{\\pi}A^{\\frac{2}{3}}}`\n",
      "\n",
      "    Compactness 1 is a measure of how compact the shape of the tumor is\n",
      "    relative to a sphere (most compact). It is a dimensionless measure,\n",
      "    independent of scale and orientation. Compactness 1 is defined as the\n",
      "    ratio of volume to the :math:`\\sqrt{\\text{surface area}^3}`. This is a measure of the\n",
      "    compactness of the shape of the image ROI\n",
      "    \n",
      "Sphericity\n",
      "\n",
      "    Calculate the Sphericity of the tumor region.\n",
      "\n",
      "    :math:`sphericity = \\frac{\\pi^{\\frac{1}{3}}(6V)^{\\frac{2}{3}}}{A}`\n",
      "\n",
      "    Sphericity is a measure of the roundness of the shape of the tumor region\n",
      "    relative to a sphere. This is another measure of the compactness of a tumor.\n",
      "    \n",
      "Maximum2DDiameterSlice\n",
      "\n",
      "    Calculate the largest pairwise euclidean distance between tumor surface voxels in the row-column plane.\n",
      "    \n",
      "Elongation\n",
      "\n",
      "\n",
      "    \n",
      "SurfaceVolumeRatio\n",
      "\n",
      "    Calculate the surface area to volume ratio of the tumor region\n",
      "\n",
      "    :math:`surface\\ to\\ volume\\ ratio = \\frac{A}{V}`\n",
      "    \n",
      "Volume\n",
      "\n",
      "    Calculate the volume of the tumor region in cubic millimeters.\n",
      "    \n",
      "Roundness\n",
      "\n",
      "\n",
      "    \n",
      "SphericalDisproportion\n",
      "\n",
      "    Calculate the Spherical Disproportion of the tumor region.\n",
      "\n",
      "    :math:`spherical\\ disproportion = \\frac{A}{4\\pi R^2}`\n",
      "\n",
      "    Where :math:`R` is the radius of a sphere with the same volume as the tumor.\n",
      "\n",
      "    Spherical Disproportion is the ratio of the surface area of the\n",
      "    tumor region to the surface area of a sphere with the same\n",
      "    volume as the tumor region.\n",
      "    \n",
      "Flatness\n",
      "\n",
      "\n",
      "    \n",
      "SurfaceArea\n",
      "\n",
      "    Calculate the surface area of the tumor region in square millimeters.\n",
      "\n",
      "    :math:`A = \\displaystyle\\sum^{N}_{i=1}{\\frac{1}{2}|\\textbf{a}_i\\textbf{b}_i \\times \\textbf{a}_i\\textbf{c}_i|}`\n",
      "\n",
      "    Where:\n",
      "\n",
      "    :math:`N` is the number of triangles forming the surface of the volume\n",
      "\n",
      "    :math:`a_ib_i` and :math:`a_ic_i` are the edges of the :math:`i`\\ :sup:`th` triangle formed by points :math:`a_i`,\n",
      "    :math:`b_i` and :math:`c_i`\n",
      "\n",
      "    \n",
      "Maximum2DDiameterColumn\n",
      "\n",
      "    Calculate the largest pairwise euclidean distance between tumor surface voxels in the row-slice plane.\n",
      "    \n",
      "Maximum2DDiameterRow\n",
      "\n",
      "    Calculate the largest pairwise euclidean distance between tumor surface voxels in the column-slice plane.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Print out the docstrings of the enabled features\n",
    "print('Will calculate the following shape features: ')\n",
    "for f in shapeFeatures.enabledFeatures.keys():\n",
    "  print(f)\n",
    "  print(eval('shapeFeatures.get' + f + 'FeatureValue.__doc__'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating shape features...\n",
      "done\n",
      "Calculated shape features: \n",
      "   Maximum3DDiameter : 65.5366145873\n",
      "   Compactness2 : 0.114127701901\n",
      "   Maximum2DDiameterSlice : 47.2187913633\n",
      "   Sphericity : 0.485061744222\n",
      "   Compactness1 : 26.7546787215\n",
      "   Elongation : 1.7789885567\n",
      "   SurfaceVolumeRatio : 0.392308261863\n",
      "   Volume : 16412.6586914\n",
      "   Flatness : 1.21918505897\n",
      "   SphericalDisproportion : 2.06159321347\n",
      "   Roundness : 0.61469066615\n",
      "   SurfaceArea : 6438.82160378\n",
      "   Maximum2DDiameterColumn : 44.5487904052\n",
      "   Maximum2DDiameterRow : 61.5801767135\n"
     ]
    }
   ],
   "source": [
    "# Calculate the features and print(out result)\n",
    "print('Calculating shape features...',)\n",
    "shapeFeatures.calculateFeatures()\n",
    "print('done')\n",
    "\n",
    "print('Calculated shape features: ')\n",
    "for (key, val) in six.iteritems(shapeFeatures.featureValues):\n",
    "  print('  ', key, ':', val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate GLCM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glcmFeatures = glcm.RadiomicsGLCM(croppedImage, croppedMask, **kwargs)\n",
    "\n",
    "# Set the features to be calculated\n",
    "# glcmFeatures.enableFeatureByName('SumEntropy', True)\n",
    "glcmFeatures.enableAllFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will calculate the following GLCM features: \n",
      "SumVariance\n",
      "\n",
      "    Using coefficients :math:`p_{x+y}` and SumEntropy (SE) calculate and return the mean Sum Variance.\n",
      "\n",
      "    :math:`sum\\ variance = \\displaystyle\\sum^{2N_g}_{k=2}{(k-SE)^2p_{x+y}(k)}`\n",
      "\n",
      "    Sum Variance is a measure of heterogeneity that places higher weights on\n",
      "    neighboring intensity level pairs that deviate more from the mean.\n",
      "    \n",
      "Homogeneity1\n",
      "\n",
      "    Calculate and return the mean Homogeneity 1.\n",
      "\n",
      "    :math:`homogeneity\\ 1 = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{\\frac{p(i,j)}{1+|i-j|}}`\n",
      "\n",
      "    Homogeneity 1 is a measure of the similarity in intensity values for\n",
      "    neighboring voxels. It is a measure of local homogeneity that increases\n",
      "    with less contrast in the window.\n",
      "    \n",
      "Homogeneity2\n",
      "\n",
      "    Calculate and return the mean Homogeneity 2.\n",
      "\n",
      "    :math:`homogeneity\\ 2 = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{\\frac{p(i,j)}{1+|i-j|^2}}`\n",
      "\n",
      "    Homogeneity 2 is a measure of the similarity in intensity values\n",
      "    for neighboring voxels.\n",
      "    \n",
      "ClusterShade\n",
      "\n",
      "    Using coefficients :math:`\\mu_x` and :math:`\\mu_y`, calculate and return the mean Cluster Shade.\n",
      "\n",
      "    :math:`cluster\\ shade = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{\\big(i+j-\\mu_x(i)-\\mu_y(j)\\big)^3p(i,j)}`\n",
      "\n",
      "    Cluster Shade is a measure of the skewness and uniformity of the GLCM.\n",
      "    A higher cluster shade implies greater asymmetry about the mean.\n",
      "    \n",
      "MaximumProbability\n",
      "\n",
      "    Calculate and return the mean Maximum Probability.\n",
      "\n",
      "    :math:`maximum\\ probability = \\max\\big(p(i,j)\\big)`\n",
      "\n",
      "    Maximum Probability is occurrences of the most predominant pair of\n",
      "    neighboring intensity values.\n",
      "    \n",
      "Idmn\n",
      "\n",
      "    Calculate and return the mean Inverse Difference Moment Normalized.\n",
      "\n",
      "    :math:`IDMN = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{ \\frac{p(i,j)}{1+\\left(\\frac{|i-j|^2}{N_g^2}\\right)} }`\n",
      "\n",
      "    IDMN (inverse difference moment normalized)  is a measure of the local\n",
      "    homogeneity of an image. IDMN weights are the inverse of the Contrast\n",
      "    weights (decreasing exponentially from the diagonal :math:`i=j` in the GLCM).\n",
      "    Unlike Homogeneity2, IDMN normalizes the square of the difference between\n",
      "    neighboring intensity values by dividing over the square of the total\n",
      "    number of discrete intensity values.\n",
      "    \n",
      "SumVariance2\n",
      "\n",
      "    Using coefficients :math:`p_{x+y}` and SumAvarage (SA) calculate and return the mean Sum Variance 2.\n",
      "    :math:`sum\\ variance\\ 2 = \\displaystyle\\sum^{2N_g}_{k=2}{(k-SA)^2p_{x+y}(k)}`\n",
      "\n",
      "    Sum Variance 2 is a measure of heterogeneity that places higher weights on\n",
      "    neighboring intensity level pairs that deviate more from the mean.\n",
      "\n",
      "    This formula differs from SumVariance in that instead of subtracting the SumEntropy from the intensity,\n",
      "    it subtracts the SumAvarage, which is the mean of intensities and not its entropy\n",
      "    \n",
      "Contrast\n",
      "\n",
      "    Using the squared difference between gray values of neighbouring paris, calculate and return the mean Contrast.\n",
      "\n",
      "    :math:`contrast = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{(i-j)^2p(i,j)}`\n",
      "\n",
      "    Contrast is a measure of the local intensity variation, favoring :math:`P(i,j)`\n",
      "    values away from the diagonal :math:`(i = j)`. A larger value correlates with\n",
      "    a greater disparity in intensity values among neighboring voxels.\n",
      "    \n",
      "DifferenceEntropy\n",
      "\n",
      "    Using coefficient :math:`p_{x-y}`, calculate and return the mean Difference Entropy.\n",
      "\n",
      "    :math:`difference\\ entropy = \\displaystyle\\sum^{N_g-1}_{k=0}{p_{x-y}(k)\\log_2\\big(p_{x-y}(k)+\\epsilon\\big)}`\n",
      "\n",
      "    Difference Entropy is a measure of the randomness/variability\n",
      "    in neighborhood intensity value differences.\n",
      "    \n",
      "InverseVariance\n",
      "\n",
      "    Calculate and return the mean Inverse Variance.\n",
      "\n",
      "    :math:`inverse\\ variance = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{\\frac{p(i,j)}{|i-j|^2}}, i \\neq j`\n",
      "    \n",
      "Dissimilarity\n",
      "\n",
      "    Calculate and return the mean Dissimilarity.\n",
      "\n",
      "    :math:`dissimilarity = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{|i-j|p(i,j)}`\n",
      "\n",
      "    Dissimilarity is a measure of local intensity variation defined as the mean absolute difference between the\n",
      "    neighbouring pairs. A larger value correlates with a greater disparity in intensity values\n",
      "    among neighboring voxels.\n",
      "    \n",
      "SumAverage\n",
      "\n",
      "    Coefficient :math:`p_{x+y}`, calculate and return the mean Sum Average.\n",
      "\n",
      "    :math:`sum\\ average = \\displaystyle\\sum^{2N_g}_{k=2}{p_{x+y}(k)k}`\n",
      "\n",
      "    Sum Average measures the relationship between occurrences of pairs\n",
      "    with lower intensity values and occurrences of pairs with higher intensity\n",
      "    values.\n",
      "    \n",
      "DifferenceVariance\n",
      "\n",
      "    Using coefficients :math:`p_{x-y}` and DifferenceAverage (DA) calculate and return the mean Difference Variance.\n",
      "\n",
      "    :math:`Difference\\ variance = \\displaystyle\\sum^{N_g-1}_{k=0}{(1-DA)^2\\textbf{P}_{x-y}(k)}`\n",
      "\n",
      "    Difference Variance is a measure of heterogeneity that places higher weights on\n",
      "    differing intensity level pairs that deviate more from the mean.\n",
      "    \n",
      "Idn\n",
      "\n",
      "    Calculate and return the mean Inverse Difference Normalized.\n",
      "\n",
      "    :math:`IDN = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{ \\frac{p(i,j)}{1+\\left(\\frac{|i-j|}{N_g}\\right)} }`\n",
      "\n",
      "    IDN (inverse difference normalized) is another measure of the local\n",
      "    homogeneity of an image. Unlike Homogeneity1, IDN normalizes the difference\n",
      "    between the neighboring intensity values by dividing over the total number\n",
      "    of discrete intensity values.\n",
      "    \n",
      "Idm\n",
      "\n",
      "    Calculate and return the mean Inverse Difference Moment.\n",
      "\n",
      "    :math:`IDM = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{ \\frac{\\textbf{P}(i,j)}{1+|i-j|^2} }`\n",
      "\n",
      "    IDM (inverse difference moment)  is a measure of the local\n",
      "    homogeneity of an image. IDM weights are the inverse of the Contrast\n",
      "    weights (decreasing exponentially from the diagonal i=j in the GLCM).\n",
      "    \n",
      "Correlation\n",
      "\n",
      "    Using coefficients :math:`\\mu_x`, :math:`\\mu_y`, :math:`\\sigma_x` and :math:`\\sigma_y`, calculate and return the\n",
      "    mean Correlation.\n",
      "\n",
      "    :math:`correlation = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_g}_{j=1}{p(i,j)ij-\\mu_x(i)\\mu_y(j)}}{\\sigma_x(i)\\sigma_y(j)}`\n",
      "\n",
      "    Correlation is a value between 0 (uncorrelated) and 1 (perfectly correlated) showing the\n",
      "    linear dependency of gray level values to their respective voxels in the GLCM.\n",
      "    \n",
      "Autocorrelation\n",
      "\n",
      "    Calculate and return the mean Autocorrelation.\n",
      "\n",
      "    :math:`autocorrelation = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{p(i,j)ij}`\n",
      "\n",
      "    Autocorrelation is a measure of the magnitude of the\n",
      "    fineness and coarseness of texture.\n",
      "    \n",
      "SumEntropy\n",
      "\n",
      "    Using coefficient :math:`p_{x+y}`, calculate and return the mean Sum Entropy.\n",
      "\n",
      "    :math:`sum\\ entropy = \\displaystyle\\sum^{2N_g}_{k=2}{p_{x+y}(k)\\log_2\\big(p_{x+y}(k)+\\epsilon\\big)}`\n",
      "\n",
      "    Sum Entropy is a sum of neighborhood intensity value differences.\n",
      "    \n",
      "AverageIntensity\n",
      "\n",
      "    Return the mean gray level intensity of the :math:`i` distribution.\n",
      "\n",
      "    :math:`\\mu_x = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{p(i,j)i}`\n",
      "\n",
      "    N.B. As this formula represents the average of the distribution of :math:`i`, it is independent from the\n",
      "    distribution of :math:`j`. Therefore, only use this formula if the GLCM is symmetrical, where both distrubutions\n",
      "    are equal.\n",
      "    \n",
      "Energy\n",
      "\n",
      "    Calculate and return the mean Energy.\n",
      "\n",
      "    :math:`energy = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{\\big(p(i,j)\\big)^2}`\n",
      "\n",
      "    Energy (or Angular Second Moment)is a measure of homogeneous patterns\n",
      "    in the image. A greater Energy implies that there are more instances\n",
      "    of intensity value pairs in the image that neighbor each other at\n",
      "    higher frequencies.\n",
      "    \n",
      "SumSquares\n",
      "\n",
      "    Using coefficients :math:`i` and math:`\\mu_x`, calculate and return the mean Sum of Squares (also known as\n",
      "    Variance) of the :math:`i` distribution.\n",
      "\n",
      "    :math:`sum\\ squares = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{(i-\\mu_x)^2p(i,j)}`\n",
      "\n",
      "    Sum of Squares or Variance is a measure in the distribution of neigboring intensity level pairs\n",
      "    about the mean intensity level in the GLCM.\n",
      "\n",
      "    N.B. This formula represents the variance of the distribution of :math:`i` and is independent from the distribution\n",
      "    of :math:`j`. Therefore, only use this formula if the GLCM is symmetrical, where VAR(i) is equal to VAR(j).\n",
      "    \n",
      "ClusterProminence\n",
      "\n",
      "    Using coefficients :math:`\\mu_x` and :math:`\\mu_y`, calculate and return the mean Cluster Prominence.\n",
      "\n",
      "    :math:`cluster\\ prominence = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{\\big( i+j-\\mu_x(i)-\\mu_y(j)\\big)^4p(i,j)}`\n",
      "\n",
      "    Cluster Prominence is a measure of the skewness and asymmetry of the GLCM.\n",
      "    A higher values implies more asymmetry about the mean while a lower value\n",
      "    indicates a peak near the mean value and less variation about the mean.\n",
      "    \n",
      "Entropy\n",
      "\n",
      "    Calculate and return the mean Entropy.\n",
      "\n",
      "    :math:`entropy = -\\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{p(i,j)\\log_2\\big(p(i,j)+\\epsilon\\big)}`\n",
      "\n",
      "    Entropy is a measure of the randomness/variability in neighborhood intensity values.\n",
      "    \n",
      "Imc2\n",
      "\n",
      "    Using coefficients :math:`HXY` and :math:`HXY2`, calculate and return the mean Informal Measure of Correlation 2.\n",
      "\n",
      "    :math:`IMC\\ 2 = \\sqrt{1-e^{-2(HXY2-HXY)}}`\n",
      "    \n",
      "Imc1\n",
      "\n",
      "    Using coefficients :math:`HX`, :math:`HY`, :math:`HXY` and :math:`HXY1`, calculate and return the mean Informal\n",
      "    Measure of Correlation 1.\n",
      "\n",
      "    :math:`IMC\\ 1 = \\frac{HXY-HXY1}{\\max\\{HX,HY\\}}`\n",
      "    \n",
      "DifferenceAverage\n",
      "\n",
      "    Using coefficient :math:`p_{x-y}`, calculate and return the mean Difference Average.\n",
      "\n",
      "    :math:`Difference\\ average = \\displaystyle\\sum^{N_g-1}_{k=0}{k\\textbf{P}_{x-y}(k)}`\n",
      "\n",
      "    Difference Average measures the relationship between occurrences of pairs\n",
      "    with similar intensity values and occurrences of pairs with differing intensity\n",
      "    values.\n",
      "    \n",
      "Id\n",
      "\n",
      "    Calculate and return the mean Inverse Difference.\n",
      "\n",
      "    :math:`ID = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{ \\frac{\\textbf{P}(i,j)}{1+|i-j|} }`\n",
      "\n",
      "    ID (inverse difference) is another measure of the local homogeneity of an image.\n",
      "    With more uniform gray levels, the denominator will remain low, resulting in a higher overall value.\n",
      "    \n",
      "ClusterTendency\n",
      "\n",
      "    Using coefficients :math:`\\mu_x` and :math:`\\mu_y`, calculate and return the mean Cluster Tendency.\n",
      "\n",
      "    :math:`cluster\\ prominence = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{\\big(i+j-\\mu_x(i)-\\mu_y(j)\\big)^2p(i,j)}`\n",
      "\n",
      "    Cluster Tendency is a measure of groupings of voxels with similar gray-level values.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Print out the docstrings of the enabled features\n",
    "print('Will calculate the following GLCM features: ')\n",
    "for f in glcmFeatures.enabledFeatures.keys():\n",
    "  print(f)\n",
    "  print(eval('glcmFeatures.get' + f + 'FeatureValue.__doc__'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating GLCM features...\n",
      "done\n",
      "Calculated GLCM features: \n",
      "   SumVariance : 895.891808819\n",
      "   Homogeneity1 : 0.276140402104\n",
      "   Homogeneity2 : 0.189156155892\n",
      "   ClusterShade : -52.9707943386\n",
      "   MaximumProbability : 0.00792784235012\n",
      "   Idmn : 0.957796447609\n",
      "   SumVariance2 : 103.142793792\n",
      "   Contrast : 52.2310659277\n",
      "   DifferenceEntropy : 3.79686113536\n",
      "   InverseVariance : 0.188666637795\n",
      "   Entropy : 8.79428086119\n",
      "   Dissimilarity : 5.58932678922\n",
      "   DifferenceVariance : 17.6107741076\n",
      "   Idn : 0.866370546902\n",
      "   Idm : 0.189156155892\n",
      "   Correlation : 0.335214788202\n",
      "   Autocorrelation : 292.684050471\n",
      "   SumEntropy : 5.31547876648\n",
      "   AverageIntensity : 17.1242601309\n",
      "   Energy : 0.00290880217681\n",
      "   SumSquares : 39.9781084143\n",
      "   ClusterProminence : 26251.1709801\n",
      "   SumAverage : 33.4497492152\n",
      "   Imc2 : 0.692033706271\n",
      "   Imc1 : -0.091940840043\n",
      "   DifferenceAverage : 5.58932678922\n",
      "   Id : 0.276140402104\n",
      "   ClusterTendency : 103.142793792\n"
     ]
    }
   ],
   "source": [
    "# Calculate the features and print(out result)\n",
    "print('Calculating GLCM features...',)\n",
    "glcmFeatures.calculateFeatures()\n",
    "print('done')\n",
    "\n",
    "print('Calculated GLCM features: ')\n",
    "for (key, val) in six.iteritems(glcmFeatures.featureValues):\n",
    "  print('  ', key, ':', val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate GLRLM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glrlmFeatures = glrlm.RadiomicsGLRLM(croppedImage, croppedMask, **kwargs)\n",
    "\n",
    "# Set the features to be calculated\n",
    "# glrlmFeatures.enableFeatureByName('ShortRunEmphasis', True)\n",
    "glrlmFeatures.enableAllFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will calculate the following GLRLM features: \n",
      "ShortRunLowGrayLevelEmphasis\n",
      "\n",
      "    Calculate and return the mean Short Run Low Gray Level Emphasis (SRLGLE) value for all GLRLMs.\n",
      "\n",
      "    :math:`SRLGLE = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\frac{\\textbf{P}(i,j|\\theta)}{i^2j^2}}}{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}}`\n",
      "\n",
      "    Measures the joint distribution of shorter run lengths with lower gray-level values.\n",
      "    \n",
      "GrayLevelVariance\n",
      "\n",
      "    Calculate and return the Gray Level Variance (GLV) value.\n",
      "\n",
      "    :math:`GLV = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_r}_{j=1}{p(i,j|\\theta)(i - \\mu)^2}`, where\n",
      "\n",
      "    :math:`\\mu = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_r}_{j=1}{p(i,j|\\theta)i}`\n",
      "\n",
      "    Measures the variance in gray level intensity for the runs.\n",
      "    \n",
      "LowGrayLevelRunEmphasis\n",
      "\n",
      "    Calculate and return the mean Low Gray Level Run Emphasis (LGLRE) value for all GLRLMs.\n",
      "\n",
      "    :math:`LGLRE = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\frac{\\textbf{P}(i,j|\\theta)}{i^2}}}{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}}`\n",
      "\n",
      "    Measures the distribution of low gray-level values, with a higher value indicating a greater\n",
      "    concentration of low gray-level values in the image.\n",
      "    \n",
      "GrayLevelNonUniformityNormalized\n",
      "\n",
      "    Calculate and return the Gray Level Non-Uniformity Normalized (GLNN) value.\n",
      "\n",
      "    :math:`GLNN = \\frac{\\sum^{N_g}_{i=1}\\left(\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}\\right)^2}{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}^2}`\n",
      "\n",
      "    Measures the similarity of gray-level intensity values in the image, where a lower GLNN value\n",
      "    correlates with a greater similarity in intensity values. This is the normalized version of the GLN formula.\n",
      "    \n",
      "RunVariance\n",
      "\n",
      "    Calculate and return the Run Variance (RV) value.\n",
      "\n",
      "    :math:`RV = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_r}_{j=1}{p(i,j|\\theta)(j - \\mu)^2}`, where\n",
      "\n",
      "    :math:`\\mu = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_r}_{j=1}{p(i,j|\\theta)j}`\n",
      "\n",
      "    Measures the variance in runs for the run lengths.\n",
      "    \n",
      "GrayLevelNonUniformity\n",
      "\n",
      "    Calculate and return the mean Gray Level Non-Uniformity (GLN) value for all GLRLMs.\n",
      "\n",
      "    :math:`GLN = \\frac{\\sum^{N_g}_{i=1}\\left(\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}\\right)^2}{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}}`\n",
      "\n",
      "    Measures the similarity of gray-level intensity values in the image, where a lower GLN value\n",
      "    correlates with a greater similarity in intensity values.\n",
      "    \n",
      "LongRunEmphasis\n",
      "\n",
      "    Calculate and return the mean Long Run Emphasis (LRE) value for all GLRLMs.\n",
      "\n",
      "    :math:`LRE = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)j^2}}{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}}`\n",
      "\n",
      "    A measure of the distribution of long run lengths, with a greater value indicative\n",
      "    of longer run lengths and more coarse structural textures.\n",
      "    \n",
      "ShortRunHighGrayLevelEmphasis\n",
      "\n",
      "    Calculate and return the mean Short Run High Gray Level Emphasis (SRHGLE) value for all GLRLMs.\n",
      "\n",
      "    :math:`SRHGLE = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\frac{\\textbf{P}(i,j|\\theta)i^2}{j^2}}}{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}}`\n",
      "\n",
      "    Measures the joint distribution of shorter run lengths with higher gray-level values.\n",
      "    \n",
      "RunLengthNonUniformity\n",
      "\n",
      "    Calculate and return the mean Run Length Non-Uniformity (RLN) value for all GLRLMs.\n",
      "\n",
      "    :math:`RLN = \\frac{\\sum^{N_r}_{j=1}\\left(\\sum^{N_g}_{i=1}{\\textbf{P}(i,j|\\theta)}\\right)^2}{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}}`\n",
      "\n",
      "    Measures the similarity of run lengths throughout the image, with a lower value indicating\n",
      "    more homogeneity among run lengths in the image.\n",
      "    \n",
      "ShortRunEmphasis\n",
      "\n",
      "    Calculate and return the mean Short Run Emphasis (SRE) value for all GLRLMs.\n",
      "\n",
      "    :math:`SRE = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\frac{\\textbf{P}(i,j|\\theta)}{i^2}}}{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}}`\n",
      "\n",
      "    A measure of the distribution of short run lengths, with a greater value indicative\n",
      "    of shorter run lengths and more fine textural textures.\n",
      "    \n",
      "LongRunHighGrayLevelEmphasis\n",
      "\n",
      "    Calculate and return the mean Long Run High Gray Level Emphasis (LRHGLE) value for all GLRLMs.\n",
      "\n",
      "    :math:`LRHGLRE = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)i^2j^2}}{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}}`\n",
      "\n",
      "    Measures the joint distribution of long run lengths with higher gray-level values.\n",
      "    \n",
      "RunPercentage\n",
      "\n",
      "    Calculate and return the mean Run Percentage (RP) value for all GLRLMs.\n",
      "\n",
      "    :math:`RP = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_r}_{j=1}{\\frac{\\textbf{P}(i,j|\\theta)}{N_p}}`\n",
      "\n",
      "    Measures the homogeneity and distribution of runs of an image.\n",
      "    \n",
      "LongRunLowGrayLevelEmphasis\n",
      "\n",
      "    Calculate and return the mean Long Run Low Gray Level Emphasis (LRLGLE) value for all GLRLMs.\n",
      "\n",
      "    :math:`LRLGLRE = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\frac{\\textbf{P}(i,j|\\theta)j^2}{i^2}}}{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}}`\n",
      "\n",
      "    Measures the joint distribution of long run lengths with lower gray-level values.\n",
      "    \n",
      "RunEntropy\n",
      "\n",
      "    Calculate and return the Run Entropy (RE) value.\n",
      "\n",
      "    :math:`RE = -\\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_r}_{j=1}{p(i,j|\\theta)\\log_{2}(p(i,j|\\theta)+\\epsilon)}`\n",
      "\n",
      "    Here, :math:`\\epsilon` is an arbitrarily small positive number (:math:`\\approx 2.2\\times10^{-16}`).\n",
      "    \n",
      "HighGrayLevelRunEmphasis\n",
      "\n",
      "    Calculate and return the mean High Gray Level Run Emphasis (HGLRE) value for all GLRLMs.\n",
      "\n",
      "    :math:`HGLRE = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)i^2}}{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}}`\n",
      "\n",
      "    Measures the distribution of the higher gray-level values, with a higher value indicating\n",
      "    a greater concentration of high gray-level values in the image.\n",
      "    \n",
      "RunLengthNonUniformityNormalized\n",
      "\n",
      "    Calculate and return the mean Run Length Non-Uniformity Normalized (RLNN) value for all GLRLMs.\n",
      "\n",
      "    :math:`RLNN = \\frac{\\sum^{N_r}_{j=1}\\left(\\sum^{N_g}_{i=1}{\\textbf{P}(i,j|\\theta)}\\right)^2}{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}}`\n",
      "\n",
      "    Measures the similarity of run lengths throughout the image, with a lower value indicating\n",
      "    more homogeneity among run lengths in the image. This is the normalized version of the RLN formula.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Print out the docstrings of the enabled features\n",
    "print('Will calculate the following GLRLM features: ')\n",
    "for f in glrlmFeatures.enabledFeatures.keys():\n",
    "  print(f)\n",
    "  print(eval('glrlmFeatures.get' + f + 'FeatureValue.__doc__'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating GLRLM features...\n",
      "done\n",
      "Calculated GLRLM features: \n",
      "   ShortRunLowGrayLevelEmphasis : 0.00822976624416\n",
      "   GrayLevelVariance : 39.118151022\n",
      "   LowGrayLevelRunEmphasis : 0.00860039789166\n",
      "   GrayLevelNonUniformityNormalized : 0.0451412381498\n",
      "   RunVariance : 0.0847945778959\n",
      "   GrayLevelNonUniformity : 175.635192315\n",
      "   LongRunEmphasis : 1.22684403826\n",
      "   ShortRunHighGrayLevelEmphasis : 268.974179841\n",
      "   RunLengthNonUniformity : 3500.04323157\n",
      "   ShortRunEmphasis : 0.955939173141\n",
      "   LongRunHighGrayLevelEmphasis : 341.286579098\n",
      "   RunPercentage : 0.940406463249\n",
      "   LongRunLowGrayLevelEmphasis : 0.0106011704787\n",
      "   RunEntropy : 4.91503800316\n",
      "   HighGrayLevelRunEmphasis : 281.066493909\n",
      "   RunLengthNonUniformityNormalized : 0.895049465948\n"
     ]
    }
   ],
   "source": [
    "# Calculate the features and print(out result)\n",
    "print('Calculating GLRLM features...',)\n",
    "glrlmFeatures.calculateFeatures()\n",
    "print('done')\n",
    "\n",
    "print('Calculated GLRLM features: ')\n",
    "for (key, val) in six.iteritems(glrlmFeatures.featureValues):\n",
    "  print('  ', key, ':', val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Features using Laplacian of Gaussian Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating features on filtered images is very similar to calculating features on the original image. All filters in PyRadiomics have the same input and output signature, and there is even one for applying no filter. This enables to loop over a list of requested filters and apply them in the same piece of code. It is applied like this in the execute function in feature extractor. The input for the filters is the image, with additional keywords. If no additional keywords are supplied, the filter uses default values where applicable. It returns a [generator object](https://docs.python.org/2/reference/simple_stmts.html?#yield), allowing to define the generators to be applied before the filters functions are actually called."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Firstorder on LoG filtered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tComputing LoG with sigma 1\n",
      "\tComputing LoG with sigma 3\n",
      "\tComputing LoG with sigma 5\n"
     ]
    }
   ],
   "source": [
    "logFeatures = {}\n",
    "sigmaValues = [1.0, 3.0, 5.0]\n",
    "for logImage, inputImageName, inputKwargs in imageoperations.getLoGImage(image, sigma=sigmaValues, verbose=True):\n",
    "  logImage, croppedMask, bb = imageoperations.cropToTumorMask(logImage, mask)\n",
    "  logFirstorderFeatures = firstorder.RadiomicsFirstOrder(logImage, croppedMask, **inputKwargs)\n",
    "  logFirstorderFeatures.enableAllFeatures()\n",
    "  logFirstorderFeatures.calculateFeatures()\n",
    "  logFeatures[inputImageName] = logFirstorderFeatures.featureValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   log-sigma-3-0-mm-3D_InterquartileRange : 103.158138275\n",
      "   log-sigma-3-0-mm-3D_Skewness : -0.498386343995\n",
      "   log-sigma-3-0-mm-3D_Uniformity : 0.0906478492348\n",
      "   log-sigma-3-0-mm-3D_MeanAbsoluteDeviation : 64.3312024633\n",
      "   log-sigma-3-0-mm-3D_Energy : 15235011555.6\n",
      "   log-sigma-3-0-mm-3D_RobustMeanAbsoluteDeviation : 43.3779243984\n",
      "   log-sigma-3-0-mm-3D_Median : -73.3129653931\n",
      "   log-sigma-3-0-mm-3D_TotalEnergy : 60441635199.8\n",
      "   log-sigma-3-0-mm-3D_Maximum : 114.296691895\n",
      "   log-sigma-3-0-mm-3D_RootMeanSquared : 1919.01616706\n",
      "   log-sigma-3-0-mm-3D_90Percentile : 13.9173410416\n",
      "   log-sigma-3-0-mm-3D_Minimum : -354.335235596\n",
      "   log-sigma-3-0-mm-3D_Entropy : 3.72121444058\n",
      "   log-sigma-3-0-mm-3D_StandardDeviation : 81.9760118492\n",
      "   log-sigma-3-0-mm-3D_Range : 468.63192749\n",
      "   log-sigma-3-0-mm-3D_Variance : 6720.06651871\n",
      "   log-sigma-3-0-mm-3D_10Percentile : -197.017340088\n",
      "   log-sigma-3-0-mm-3D_Kurtosis : 3.18336583197\n",
      "   log-sigma-3-0-mm-3D_Mean : -82.7355469484\n",
      "   log-sigma-1-0-mm-3D_InterquartileRange : 81.8767185211\n",
      "   log-sigma-1-0-mm-3D_Skewness : -0.220905251704\n",
      "   log-sigma-1-0-mm-3D_Uniformity : 0.114235313372\n",
      "   log-sigma-1-0-mm-3D_MeanAbsoluteDeviation : 49.6646616511\n",
      "   log-sigma-1-0-mm-3D_Energy : 16201455197.6\n",
      "   log-sigma-1-0-mm-3D_RobustMeanAbsoluteDeviation : 34.3094515237\n",
      "   log-sigma-1-0-mm-3D_Median : -18.9197921753\n",
      "   log-sigma-1-0-mm-3D_TotalEnergy : 64275792715.1\n",
      "   log-sigma-1-0-mm-3D_Maximum : 164.726760864\n",
      "   log-sigma-1-0-mm-3D_RootMeanSquared : 1978.94740333\n",
      "   log-sigma-1-0-mm-3D_90Percentile : 54.7903442383\n",
      "   log-sigma-1-0-mm-3D_Minimum : -255.259628296\n",
      "   log-sigma-1-0-mm-3D_Entropy : 3.37004955078\n",
      "   log-sigma-1-0-mm-3D_StandardDeviation : 62.6969503974\n",
      "   log-sigma-1-0-mm-3D_Range : 419.98638916\n",
      "   log-sigma-1-0-mm-3D_Variance : 3930.90758913\n",
      "   log-sigma-1-0-mm-3D_10Percentile : -104.93405304\n",
      "   log-sigma-1-0-mm-3D_Kurtosis : 3.07182438072\n",
      "   log-sigma-1-0-mm-3D_Mean : -22.0460274432\n",
      "   log-sigma-5-0-mm-3D_InterquartileRange : 106.342716217\n",
      "   log-sigma-5-0-mm-3D_Skewness : -0.30549686903\n",
      "   log-sigma-5-0-mm-3D_Uniformity : 0.0902675928609\n",
      "   log-sigma-5-0-mm-3D_MeanAbsoluteDeviation : 63.4364264458\n",
      "   log-sigma-5-0-mm-3D_Energy : 14878729370.4\n",
      "   log-sigma-5-0-mm-3D_RobustMeanAbsoluteDeviation : 43.2562957783\n",
      "   log-sigma-5-0-mm-3D_Median : -99.1174468994\n",
      "   log-sigma-5-0-mm-3D_TotalEnergy : 59028162175.1\n",
      "   log-sigma-5-0-mm-3D_Maximum : 117.414512634\n",
      "   log-sigma-5-0-mm-3D_RootMeanSquared : 1896.44460614\n",
      "   log-sigma-5-0-mm-3D_90Percentile : -10.6977561951\n",
      "   log-sigma-5-0-mm-3D_Minimum : -347.345001221\n",
      "   log-sigma-5-0-mm-3D_Entropy : 3.71336391413\n",
      "   log-sigma-5-0-mm-3D_StandardDeviation : 80.5220089107\n",
      "   log-sigma-5-0-mm-3D_Range : 464.759513855\n",
      "   log-sigma-5-0-mm-3D_Variance : 6483.79391901\n",
      "   log-sigma-5-0-mm-3D_10Percentile : -211.974316406\n",
      "   log-sigma-5-0-mm-3D_Kurtosis : 3.11489160873\n",
      "   log-sigma-5-0-mm-3D_Mean : -105.265625411\n"
     ]
    }
   ],
   "source": [
    "# Show result\n",
    "for sigma, features in six.iteritems(logFeatures):\n",
    "  for (key, val) in six.iteritems(features):\n",
    "    laplacianFeatureName = '%s_%s' % (str(sigma), key)\n",
    "    print('  ', laplacianFeatureName, ':', val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Features using Wavelet filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Firstorder on filtered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated firstorder features with  wavelet-LHL\n",
      "Calculated firstorder features with  wavelet-LHH\n",
      "Calculated firstorder features with  wavelet-HLL\n",
      "Calculated firstorder features with  wavelet-LLH\n",
      "Calculated firstorder features with  wavelet-HLH\n",
      "Calculated firstorder features with  wavelet-HHH\n",
      "Calculated firstorder features with  wavelet-HHL\n",
      "Calculated firstorder features with  wavelet-LLL\n"
     ]
    }
   ],
   "source": [
    "waveletFeatures = {}\n",
    "for decompositionImage, decompositionName, inputKwargs in imageoperations.getWaveletImage(image):\n",
    "  decompositionImage, croppedMask, bb = imageoperations.cropToTumorMask(decompositionImage, mask)\n",
    "  waveletFirstOrderFeaturs = firstorder.RadiomicsFirstOrder(decompositionImage, croppedMask, **kwargs)\n",
    "  waveletFirstOrderFeaturs.enableAllFeatures()\n",
    "  waveletFirstOrderFeaturs.calculateFeatures()\n",
    "\n",
    "  print('Calculated firstorder features with ', decompositionName)\n",
    "  waveletFeatures[decompositionName] = waveletFirstOrderFeaturs.featureValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   wavelet-LLL_InterquartileRange : 550.594267427\n",
      "   wavelet-LLL_Skewness : 0.228846426465\n",
      "   wavelet-LLL_Uniformity : 0.0199077767278\n",
      "   wavelet-LLL_MeanAbsoluteDeviation : 293.143995944\n",
      "   wavelet-LLL_Energy : 75413385469.3\n",
      "   wavelet-LLL_RobustMeanAbsoluteDeviation : 220.739697172\n",
      "   wavelet-LLL_Median : 2244.88673609\n",
      "   wavelet-LLL_TotalEnergy : 299186404755.0\n",
      "   wavelet-LLL_Maximum : 3180.63918677\n",
      "   wavelet-LLL_RootMeanSquared : 4269.54365408\n",
      "   wavelet-LLL_90Percentile : 2739.69052111\n",
      "   wavelet-LLL_Minimum : 1468.07724103\n",
      "   wavelet-LLL_Entropy : 5.78300489052\n",
      "   wavelet-LLL_StandardDeviation : 350.172190209\n",
      "   wavelet-LLL_Range : 1712.56194574\n",
      "   wavelet-LLL_Variance : 122620.562796\n",
      "   wavelet-LLL_10Percentile : 1812.68473489\n",
      "   wavelet-LLL_Kurtosis : 2.27365643067\n",
      "   wavelet-LLL_Mean : 2255.1595095\n",
      "   wavelet-HHH_InterquartileRange : 20.3192746422\n",
      "   wavelet-HHH_Skewness : -0.0688112737241\n",
      "   wavelet-HHH_Uniformity : 0.382919979814\n",
      "   wavelet-HHH_MeanAbsoluteDeviation : 13.0759756862\n",
      "   wavelet-HHH_Energy : 16551969388.8\n",
      "   wavelet-HHH_RobustMeanAbsoluteDeviation : 8.53027450695\n",
      "   wavelet-HHH_Median : 0.109117292714\n",
      "   wavelet-HHH_TotalEnergy : 65666382462.8\n",
      "   wavelet-HHH_Maximum : 76.409965019\n",
      "   wavelet-HHH_RootMeanSquared : 2000.23985683\n",
      "   wavelet-HHH_90Percentile : 20.9238433344\n",
      "   wavelet-HHH_Minimum : -74.7556986692\n",
      "   wavelet-HHH_Entropy : 1.62781167475\n",
      "   wavelet-HHH_StandardDeviation : 17.3191286737\n",
      "   wavelet-HHH_Range : 151.165663688\n",
      "   wavelet-HHH_Variance : 299.952218016\n",
      "   wavelet-HHH_10Percentile : -21.0383130257\n",
      "   wavelet-HHH_Kurtosis : 4.32455549815\n",
      "   wavelet-HHH_Mean : 0.164876359429\n",
      "   wavelet-HLL_InterquartileRange : 53.6721220046\n",
      "   wavelet-HLL_Skewness : -0.514166044802\n",
      "   wavelet-HLL_Uniformity : 0.163587425574\n",
      "   wavelet-HLL_MeanAbsoluteDeviation : 35.7539421527\n",
      "   wavelet-HLL_Energy : 16473718010.5\n",
      "   wavelet-HLL_RobustMeanAbsoluteDeviation : 22.7497539081\n",
      "   wavelet-HLL_Median : -2.81720035755\n",
      "   wavelet-HLL_TotalEnergy : 65355936931.4\n",
      "   wavelet-HLL_Maximum : 186.246123128\n",
      "   wavelet-HLL_RootMeanSquared : 1995.50607096\n",
      "   wavelet-HLL_90Percentile : 50.8588017912\n",
      "   wavelet-HLL_Minimum : -291.543962261\n",
      "   wavelet-HLL_Entropy : 2.95573220857\n",
      "   wavelet-HLL_StandardDeviation : 48.2505612369\n",
      "   wavelet-HLL_Range : 477.790085389\n",
      "   wavelet-HLL_Variance : 2328.11665967\n",
      "   wavelet-HLL_10Percentile : -62.825323625\n",
      "   wavelet-HLL_Kurtosis : 5.09932613054\n",
      "   wavelet-HLL_Mean : -5.07735424175\n",
      "   wavelet-HHL_InterquartileRange : 22.3805938159\n",
      "   wavelet-HHL_Skewness : 0.121890250304\n",
      "   wavelet-HHL_Uniformity : 0.358701481744\n",
      "   wavelet-HHL_MeanAbsoluteDeviation : 14.4086961805\n",
      "   wavelet-HHL_Energy : 16555173614.7\n",
      "   wavelet-HHL_RobustMeanAbsoluteDeviation : 9.30098915935\n",
      "   wavelet-HHL_Median : 0.0829386441352\n",
      "   wavelet-HHL_TotalEnergy : 65679094540.6\n",
      "   wavelet-HHL_Maximum : 96.9275598216\n",
      "   wavelet-HHL_RootMeanSquared : 2000.43345645\n",
      "   wavelet-HHL_90Percentile : 23.0361222479\n",
      "   wavelet-HHL_Minimum : -100.72323161\n",
      "   wavelet-HHL_Entropy : 1.75422760497\n",
      "   wavelet-HHL_StandardDeviation : 19.2752766032\n",
      "   wavelet-HHL_Range : 197.650791432\n",
      "   wavelet-HHL_Variance : 371.536288129\n",
      "   wavelet-HHL_10Percentile : -22.0062020434\n",
      "   wavelet-HHL_Kurtosis : 4.71302154772\n",
      "   wavelet-HHL_Mean : 0.340590352114\n",
      "   wavelet-LLH_InterquartileRange : 352.672458211\n",
      "   wavelet-LLH_Skewness : -0.525773815288\n",
      "   wavelet-LLH_Uniformity : 0.0304399667913\n",
      "   wavelet-LLH_MeanAbsoluteDeviation : 205.422769392\n",
      "   wavelet-LLH_Energy : 16976478846.8\n",
      "   wavelet-LLH_RobustMeanAbsoluteDeviation : 146.79059076\n",
      "   wavelet-LLH_Median : 62.7368130338\n",
      "   wavelet-LLH_TotalEnergy : 67350532534.3\n",
      "   wavelet-LLH_Maximum : 733.850508277\n",
      "   wavelet-LLH_RootMeanSquared : 2025.7276121\n",
      "   wavelet-LLH_90Percentile : 297.911610403\n",
      "   wavelet-LLH_Minimum : -783.008892644\n",
      "   wavelet-LLH_Entropy : 5.27888924024\n",
      "   wavelet-LLH_StandardDeviation : 252.406755064\n",
      "   wavelet-LLH_Range : 1516.85940092\n",
      "   wavelet-LLH_Variance : 63709.1700018\n",
      "   wavelet-LLH_10Percentile : -370.145218743\n",
      "   wavelet-LLH_Kurtosis : 2.69674899921\n",
      "   wavelet-LLH_Mean : 9.94109078476\n",
      "   wavelet-HLH_InterquartileRange : 44.1166822626\n",
      "   wavelet-HLH_Skewness : -0.109634215845\n",
      "   wavelet-HLH_Uniformity : 0.192969183516\n",
      "   wavelet-HLH_MeanAbsoluteDeviation : 30.6419982661\n",
      "   wavelet-HLH_Energy : 16553621990.3\n",
      "   wavelet-HLH_RobustMeanAbsoluteDeviation : 18.8328798407\n",
      "   wavelet-HLH_Median : -0.78889380952\n",
      "   wavelet-HLH_TotalEnergy : 65672938804.3\n",
      "   wavelet-HLH_Maximum : 195.252851267\n",
      "   wavelet-HLH_RootMeanSquared : 2000.3397095\n",
      "   wavelet-HLH_90Percentile : 48.8399961042\n",
      "   wavelet-HLH_Minimum : -254.072696334\n",
      "   wavelet-HLH_Entropy : 2.75501833527\n",
      "   wavelet-HLH_StandardDeviation : 42.5781351256\n",
      "   wavelet-HLH_Range : 449.325547601\n",
      "   wavelet-HLH_Variance : 1812.89759078\n",
      "   wavelet-HLH_10Percentile : -48.7973652242\n",
      "   wavelet-HLH_Kurtosis : 5.96264006105\n",
      "   wavelet-HLH_Mean : -0.113489262992\n",
      "   wavelet-LHL_InterquartileRange : 71.4997770706\n",
      "   wavelet-LHL_Skewness : -0.369538595423\n",
      "   wavelet-LHL_Uniformity : 0.121366697967\n",
      "   wavelet-LHL_MeanAbsoluteDeviation : 48.962882253\n",
      "   wavelet-LHL_Energy : 16480473600.0\n",
      "   wavelet-LHL_RobustMeanAbsoluteDeviation : 30.6452121554\n",
      "   wavelet-LHL_Median : -4.09721168389\n",
      "   wavelet-LHL_TotalEnergy : 65382738281.1\n",
      "   wavelet-LHL_Maximum : 286.571219988\n",
      "   wavelet-LHL_RootMeanSquared : 1995.91519044\n",
      "   wavelet-LHL_90Percentile : 71.5796532291\n",
      "   wavelet-LHL_Minimum : -354.894733038\n",
      "   wavelet-LHL_Entropy : 3.40407739189\n",
      "   wavelet-LHL_StandardDeviation : 66.574005139\n",
      "   wavelet-LHL_Range : 641.465953026\n",
      "   wavelet-LHL_Variance : 4432.09816025\n",
      "   wavelet-LHL_10Percentile : -85.6408963114\n",
      "   wavelet-LHL_Kurtosis : 4.82046635261\n",
      "   wavelet-LHL_Mean : -5.19541075851\n",
      "   wavelet-LHH_InterquartileRange : 61.7174514326\n",
      "   wavelet-LHH_Skewness : 0.197382131364\n",
      "   wavelet-LHH_Uniformity : 0.140809788318\n",
      "   wavelet-LHH_MeanAbsoluteDeviation : 41.6368845932\n",
      "   wavelet-LHH_Energy : 16537062247.2\n",
      "   wavelet-LHH_RobustMeanAbsoluteDeviation : 26.472328543\n",
      "   wavelet-LHH_Median : -1.94009209998\n",
      "   wavelet-LHH_TotalEnergy : 65607241581.1\n",
      "   wavelet-LHH_Maximum : 279.350380757\n",
      "   wavelet-LHH_RootMeanSquared : 1999.33891946\n",
      "   wavelet-LHH_90Percentile : 63.2151706827\n",
      "   wavelet-LHH_Minimum : -324.703453683\n",
      "   wavelet-LHH_Entropy : 3.17918664471\n",
      "   wavelet-LHH_StandardDeviation : 56.4734198288\n",
      "   wavelet-LHH_Range : 604.05383444\n",
      "   wavelet-LHH_Variance : 3189.24714716\n",
      "   wavelet-LHH_10Percentile : -69.1252699084\n",
      "   wavelet-LHH_Kurtosis : 5.10438678184\n",
      "   wavelet-LHH_Mean : -1.45881510799\n"
     ]
    }
   ],
   "source": [
    "# Show result\n",
    "for decompositionName, features in six.iteritems(waveletFeatures):\n",
    "  for (key, val) in six.iteritems(features):\n",
    "    waveletFeatureName = '%s_%s' % (str(decompositionName), key)\n",
    "    print('  ', waveletFeatureName, ':', val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}